#!/usr/bin/env python3
"""
Startup script for PII Processor Frontend

This script:
1. Checks for required dependencies
2. Installs missing dependencies if needed
3. Starts the Flask server
"""

import sys
import subprocess
import os
from pathlib import Path

def check_and_install_requirements():
    """Check and install required packages"""
    print("ğŸ” Checking dependencies...")
    
    required_packages = {
        'flask': 'Flask==2.3.3',
        'flask_cors': 'Flask-CORS==4.0.0', 
        'requests': 'requests==2.31.0'
    }
    
    missing_packages = []
    
    for package, requirement in required_packages.items():
        try:
            __import__(package)
            print(f"âœ… {package} is installed")
        except ImportError:
            print(f"âŒ {package} is missing")
            missing_packages.append(requirement)
    
    if missing_packages:
        print(f"\nğŸ“¦ Installing missing packages: {', '.join(missing_packages)}")
        try:
            subprocess.check_call([
                sys.executable, '-m', 'pip', 'install'
            ] + missing_packages)
            print("âœ… All dependencies installed successfully!")
        except subprocess.CalledProcessError:
            print("âŒ Failed to install dependencies. Please install manually:")
            print(f"   pip install {' '.join(missing_packages)}")
            return False
    
    return True

def check_frontend_files():
    """Check if frontend files exist"""
    frontend_dir = Path(__file__).parent / 'frontend'
    required_files = ['index.html', 'styles.css', 'script.js']
    
    print("\nğŸ“ Checking frontend files...")
    
    if not frontend_dir.exists():
        print(f"âŒ Frontend directory not found: {frontend_dir}")
        return False
    
    for file in required_files:
        file_path = frontend_dir / file
        if file_path.exists():
            print(f"âœ… {file} found")
        else:
            print(f"âŒ {file} missing")
            return False
    
    return True

def check_ollama():
    """Check if Ollama is available"""
    print("\nğŸ¤– Checking Ollama availability...")
    try:
        import requests
        response = requests.get('http://localhost:11434/api/tags', timeout=3)
        if response.status_code == 200:
            models = response.json().get('models', [])
            print(f"âœ… Ollama is running with {len(models)} models")
            return True
        else:
            print("âš ï¸  Ollama is running but returned unexpected response")
            return False
    except Exception as e:
        print("âš ï¸  Ollama not available - LLM features will be disabled")
        print("   To enable AI features, install and start Ollama:")
        print("   https://ollama.ai/")
        return False

def main():
    """Main startup function"""
    print("ğŸš€ PII Processor Frontend Startup")
    print("=" * 50)
    
    # Check dependencies
    if not check_and_install_requirements():
        print("\nâŒ Dependency check failed. Please resolve and try again.")
        return 1
    
    # Check frontend files
    if not check_frontend_files():
        print("\nâŒ Frontend files check failed. Please ensure all files are present.")
        return 1
    
    # Check Ollama (optional)
    ollama_available = check_ollama()
    
    print("\n" + "=" * 50)
    print("âœ… All checks passed! Starting server...")
    print("\nğŸŒ The frontend will be available at:")
    print("   http://localhost:5000")
    print("\nğŸ“ Features available:")
    print("   âœ… Text anonymization/deanonymization")
    print("   âœ… File drag-and-drop (.txt files)")
    print("   âœ… Mapping file download/upload")
    print(f"   {'âœ…' if ollama_available else 'âš ï¸ '} AI-powered entity detection")
    print("\nğŸ›‘ Press Ctrl+C to stop the server")
    print("=" * 50)
    
    # Import and start the server
    try:
        from server import app
        app.run(
            host='0.0.0.0',
            port=5000,
            debug=False,  # Set to False for cleaner output
            threaded=True
        )
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Server stopped. Thank you for using PII Processor!")
        return 0
    except Exception as e:
        print(f"\nâŒ Server error: {e}")
        return 1

if __name__ == '__main__':
    sys.exit(main()) 